{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setGPU: Setting GPU to: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/homes/ebm32/escnn_jax/notebooks/../escnn/group/groups/so3group.py:20: UserWarning: `py3nj` package not found! Will use a numerical method to compute the SO(3) Clebsh-Gordan coefficents. This is much slower but the coefficients will be cached on disk.\n",
      "  warnings.warn(\"`py3nj` package not found! Will use a numerical method to compute the SO(3) Clebsh-Gordan coefficents. This is much slower but the coefficients will be cached on disk.\")\n"
     ]
    }
   ],
   "source": [
    "import setGPU\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "# import torch\n",
    "from escnn import gspaces\n",
    "from escnn import nn\n",
    "\n",
    "import equinox as eqx\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "import torch\n",
    "from jaxtyping import Array, Float, Int, PyTree, PRNGKeyArray  # https://github.com/google/jaxtyping\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.transforms import RandomRotation\n",
    "from torchvision.transforms import Pad\n",
    "from torchvision.transforms import Resize\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision.transforms import Compose\n",
    "from torchvision.transforms import InterpolationMode\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File ‘mnist_rotation_new.zip’ already there; not retrieving.\n",
      "\n",
      "Archive:  mnist_rotation_new.zip\n"
     ]
    }
   ],
   "source": [
    "# download the dataset\n",
    "!wget -nc http://www.iro.umontreal.ca/~lisa/icml2007data/mnist_rotation_new.zip\n",
    "# uncompress the zip file\n",
    "!unzip -n mnist_rotation_new.zip -d mnist_rotation_new\n",
    "\n",
    "class MnistRotDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, mode, transform=None):\n",
    "        assert mode in ['train', 'test']\n",
    "            \n",
    "        if mode == \"train\":\n",
    "            file = \"mnist_rotation_new/mnist_all_rotation_normalized_float_train_valid.amat\"\n",
    "        else:\n",
    "            file = \"mnist_rotation_new/mnist_all_rotation_normalized_float_test.amat\"\n",
    "        \n",
    "        self.transform = transform\n",
    "\n",
    "        data = np.loadtxt(file, delimiter=' ')\n",
    "            \n",
    "        self.images = data[:, :-1].reshape(-1, 28, 28).astype(np.float32)\n",
    "        self.labels = data[:, -1].astype(np.int64)\n",
    "        self.num_samples = len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        image, label = self.images[index], self.labels[index]\n",
    "        image = Image.fromarray(image, mode='F')\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "# images are padded to have shape 29x29.\n",
    "# this allows to use odd-size filters with stride 2 when downsampling a feature map in the model\n",
    "pad = Pad((0, 0, 1, 1), fill=0)\n",
    "\n",
    "# to reduce interpolation artifacts (e.g. when testing the model on rotated images),\n",
    "# we upsample an image by a factor of 3, rotate it and finally downsample it again\n",
    "resize1 = Resize(87)\n",
    "resize2 = Resize(29)\n",
    "\n",
    "totensor = ToTensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1, 29, 29)\n",
      "(1,)\n"
     ]
    }
   ],
   "source": [
    "train_transform = Compose([\n",
    "    pad,\n",
    "    resize1,\n",
    "    RandomRotation(180., interpolation=InterpolationMode.BILINEAR, expand=False),\n",
    "    resize2,\n",
    "    totensor,\n",
    "])\n",
    "\n",
    "mnist_train = MnistRotDataset(mode='train', transform=train_transform)\n",
    "train_loader = torch.utils.data.DataLoader(mnist_train, batch_size=64)\n",
    "\n",
    "\n",
    "test_transform = Compose([\n",
    "    pad,\n",
    "    totensor,\n",
    "])\n",
    "mnist_test = MnistRotDataset(mode='test', transform=test_transform)\n",
    "test_loader = torch.utils.data.DataLoader(mnist_test, batch_size=64)\n",
    "\n",
    "x, y = mnist_train[0]\n",
    "x = jnp.array(x[None, ...])\n",
    "y = jnp.array(y[None, ...])\n",
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jax.tree_util.tree_leaves(model) 4 [Array([[[[0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.]]]], dtype=float32), Array([0.4864558], dtype=float32), False, [C8_on_R2[(None, 8)]: {irrep_0 (x1)}(1)]]\n",
      "\n",
      "GroupPooling\n",
      "self._contiguous {1: True}\n",
      "1 True\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "Array slice indices must have static start/stop/step to be used with NumPy indexing syntax. Found slice(Traced<ShapedArray(int32[])>with<DynamicJaxprTrace(level=1/0)>, Traced<ShapedArray(int32[])>with<DynamicJaxprTrace(level=1/0)>, None). To index a statically sized array at a dynamic position, try lax.dynamic_slice/dynamic_update_slice (JAX does not support dynamically sized arrays within JIT compiled functions).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 99\u001b[0m\n\u001b[1;32m     91\u001b[0m model \u001b[39m=\u001b[39m eqx\u001b[39m.\u001b[39mfilter_jit(model)\u001b[39m#(input)\u001b[39;00m\n\u001b[1;32m     92\u001b[0m \u001b[39m# print(\"jax.tree_util.tree_leaves(model)\", jax.tree_util.tree_leaves(model))\u001b[39;00m\n\u001b[1;32m     93\u001b[0m \u001b[39m# print()\u001b[39;00m\n\u001b[1;32m     94\u001b[0m \u001b[39m# set_trace()\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[39m# print(type(x))\u001b[39;00m\n\u001b[1;32m     98\u001b[0m \u001b[39m# print(\"in_type\", in_type)\u001b[39;00m\n\u001b[0;32m---> 99\u001b[0m model(x)\n",
      "File \u001b[0;32m~/escnn_jax/venv/lib/python3.9/site-packages/equinox/_jit.py:103\u001b[0m, in \u001b[0;36m_JitWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m/\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 103\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39mFalse\u001b[39;49;00m, args, kwargs)\n",
      "File \u001b[0;32m~/escnn_jax/venv/lib/python3.9/site-packages/equinox/_jit.py:99\u001b[0m, in \u001b[0;36m_JitWrapper._call\u001b[0;34m(self, is_lower, args, kwargs)\u001b[0m\n\u001b[1;32m     97\u001b[0m         out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cached(dynamic, static)\n\u001b[1;32m     98\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 99\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cached(dynamic, static)\n\u001b[1;32m    100\u001b[0m \u001b[39mreturn\u001b[39;00m _postprocess(out)\n",
      "    \u001b[0;31m[... skipping hidden 12 frame]\u001b[0m\n",
      "File \u001b[0;32m~/escnn_jax/venv/lib/python3.9/site-packages/equinox/_jit.py:37\u001b[0m, in \u001b[0;36m_filter_jit_cache.<locals>.fun_wrapped\u001b[0;34m(dynamic, static)\u001b[0m\n\u001b[1;32m     35\u001b[0m fun \u001b[39m=\u001b[39m hashable_combine(dynamic_fun, static_fun)\n\u001b[1;32m     36\u001b[0m args, kwargs \u001b[39m=\u001b[39m hashable_combine(dynamic_spec, static_spec)\n\u001b[0;32m---> 37\u001b[0m out \u001b[39m=\u001b[39m fun(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     38\u001b[0m dynamic_out, static_out \u001b[39m=\u001b[39m partition(out, is_array)\n\u001b[1;32m     39\u001b[0m \u001b[39mreturn\u001b[39;00m dynamic_out, Static(static_out)\n",
      "Cell \u001b[0;32mIn[11], line 42\u001b[0m, in \u001b[0;36mCNN.__call__\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[39m# x = self.layer(x)\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers:\n\u001b[1;32m     40\u001b[0m     \u001b[39m# print(type(layer))\u001b[39;00m\n\u001b[1;32m     41\u001b[0m     \u001b[39m# print(\"x\", x.shape)\u001b[39;00m\n\u001b[0;32m---> 42\u001b[0m     x \u001b[39m=\u001b[39m layer(x)\n\u001b[1;32m     44\u001b[0m \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/escnn_jax/notebooks/../escnn/nn/modules/invariantmaps/gpool.py:126\u001b[0m, in \u001b[0;36mGroupPooling.__call__\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    123\u001b[0m out_indices \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mout_indices[s]\n\u001b[1;32m    125\u001b[0m \u001b[39mif\u001b[39;00m contiguous:\n\u001b[0;32m--> 126\u001b[0m     fm \u001b[39m=\u001b[39m \u001b[39minput\u001b[39;49m[:, in_indices[\u001b[39m0\u001b[39;49m]:in_indices[\u001b[39m1\u001b[39;49m], \u001b[39m.\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m.\u001b[39;49m]\n\u001b[1;32m    127\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    128\u001b[0m     fm \u001b[39m=\u001b[39m \u001b[39minput\u001b[39m[:, in_indices, \u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m]\n",
      "File \u001b[0;32m~/escnn_jax/venv/lib/python3.9/site-packages/jax/_src/numpy/array_methods.py:791\u001b[0m, in \u001b[0;36m_forward_operator_to_aval.<locals>.op\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    790\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mop\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs):\n\u001b[0;32m--> 791\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mgetattr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49maval, \u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m_\u001b[39;49m\u001b[39m{\u001b[39;49;00mname\u001b[39m}\u001b[39;49;00m\u001b[39m\"\u001b[39;49m)(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs)\n",
      "File \u001b[0;32m~/escnn_jax/venv/lib/python3.9/site-packages/jax/_src/numpy/lax_numpy.py:4143\u001b[0m, in \u001b[0;36m_rewriting_take\u001b[0;34m(arr, idx, indices_are_sorted, unique_indices, mode, fill_value)\u001b[0m\n\u001b[1;32m   4140\u001b[0m       \u001b[39mreturn\u001b[39;00m lax\u001b[39m.\u001b[39mdynamic_index_in_dim(arr, idx, keepdims\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m   4142\u001b[0m treedef, static_idx, dynamic_idx \u001b[39m=\u001b[39m _split_index_for_jit(idx, arr\u001b[39m.\u001b[39mshape)\n\u001b[0;32m-> 4143\u001b[0m \u001b[39mreturn\u001b[39;00m _gather(arr, treedef, static_idx, dynamic_idx, indices_are_sorted,\n\u001b[1;32m   4144\u001b[0m                unique_indices, mode, fill_value)\n",
      "File \u001b[0;32m~/escnn_jax/venv/lib/python3.9/site-packages/jax/_src/numpy/lax_numpy.py:4152\u001b[0m, in \u001b[0;36m_gather\u001b[0;34m(arr, treedef, static_idx, dynamic_idx, indices_are_sorted, unique_indices, mode, fill_value)\u001b[0m\n\u001b[1;32m   4149\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_gather\u001b[39m(arr, treedef, static_idx, dynamic_idx, indices_are_sorted,\n\u001b[1;32m   4150\u001b[0m             unique_indices, mode, fill_value):\n\u001b[1;32m   4151\u001b[0m   idx \u001b[39m=\u001b[39m _merge_static_and_dynamic_indices(treedef, static_idx, dynamic_idx)\n\u001b[0;32m-> 4152\u001b[0m   indexer \u001b[39m=\u001b[39m _index_to_gather(shape(arr), idx)  \u001b[39m# shared with _scatter_update\u001b[39;00m\n\u001b[1;32m   4153\u001b[0m   y \u001b[39m=\u001b[39m arr\n\u001b[1;32m   4155\u001b[0m   \u001b[39mif\u001b[39;00m fill_value \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/escnn_jax/venv/lib/python3.9/site-packages/jax/_src/numpy/lax_numpy.py:4404\u001b[0m, in \u001b[0;36m_index_to_gather\u001b[0;34m(x_shape, idx, normalize_indices)\u001b[0m\n\u001b[1;32m   4395\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mall\u001b[39m(_is_slice_element_none_or_constant(elt)\n\u001b[1;32m   4396\u001b[0m            \u001b[39mfor\u001b[39;00m elt \u001b[39min\u001b[39;00m (start, stop, step)):\n\u001b[1;32m   4397\u001b[0m   msg \u001b[39m=\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39mArray slice indices must have static start/stop/step to be used \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   4398\u001b[0m          \u001b[39m\"\u001b[39m\u001b[39mwith NumPy indexing syntax. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   4399\u001b[0m          \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFound slice(\u001b[39m\u001b[39m{\u001b[39;00mstart\u001b[39m}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m{\u001b[39;00mstop\u001b[39m}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m{\u001b[39;00mstep\u001b[39m}\u001b[39;00m\u001b[39m). \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4402\u001b[0m          \u001b[39m\"\u001b[39m\u001b[39mdynamic_update_slice (JAX does not support dynamically sized \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   4403\u001b[0m          \u001b[39m\"\u001b[39m\u001b[39marrays within JIT compiled functions).\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 4404\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mIndexError\u001b[39;00m(msg)\n\u001b[1;32m   4405\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m core\u001b[39m.\u001b[39mis_constant_dim(x_shape[x_axis]):\n\u001b[1;32m   4406\u001b[0m   msg \u001b[39m=\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39mCannot use NumPy slice indexing on an array dimension whose \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   4407\u001b[0m          \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39msize is not statically known (\u001b[39m\u001b[39m{\u001b[39;00mx_shape[x_axis]\u001b[39m}\u001b[39;00m\u001b[39m). \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   4408\u001b[0m          \u001b[39m\"\u001b[39m\u001b[39mTry using lax.dynamic_slice/dynamic_update_slice\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mIndexError\u001b[0m: Array slice indices must have static start/stop/step to be used with NumPy indexing syntax. Found slice(Traced<ShapedArray(int32[])>with<DynamicJaxprTrace(level=1/0)>, Traced<ShapedArray(int32[])>with<DynamicJaxprTrace(level=1/0)>, None). To index a statically sized array at a dynamic position, try lax.dynamic_slice/dynamic_update_slice (JAX does not support dynamically sized arrays within JIT compiled functions)."
     ]
    }
   ],
   "source": [
    "# %tb\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "class CNN(eqx.Module):\n",
    "    layers: list\n",
    "    # layer: eqx.Module\n",
    "    input_type: nn.FieldType\n",
    "\n",
    "    def __init__(self, key, n_classes=10):\n",
    "        keys = jax.random.split(key, 8)\n",
    "        \n",
    "        super(CNN, self).__init__()\n",
    "        self.layers = []\n",
    "        \n",
    "        # the model is equivariant under rotations by 45 degrees, modelled by C8\n",
    "        r2_act = gspaces.rot2dOnR2(N=8)\n",
    "        \n",
    "        # the input image is a scalar field, corresponding to the trivial representation\n",
    "        in_type = nn.FieldType(r2_act, [r2_act.trivial_repr])\n",
    "        \n",
    "        # we store the input type for wrapping the images into a geometric tensor during the forward pass\n",
    "        self.input_type = in_type\n",
    "\n",
    "        self.layers.extend([\n",
    "            nn.R2Conv(in_type, out_type, kernel_size=4, padding=0, use_bias=False, key=keys[0]),\n",
    "            nn.ReLU(out_type),\n",
    "            nn.GroupPooling(out_type)\n",
    "        ])\n",
    "\n",
    "\n",
    "    def __call__(self, input: Array):\n",
    "        # wrap the input tensor in a GeometricTensor\n",
    "        # (associate it with the input type)\n",
    "        in_type = self.input_type\n",
    "        # in_type = nn.FieldType(r2_act, [r2_act.trivial_repr])\n",
    "        x = nn.GeometricTensor(input, in_type)\n",
    "        # x = self.layer(x)\n",
    "        for layer in self.layers:\n",
    "            # print(type(layer))\n",
    "            # print(\"x\", x.shape)\n",
    "            x = layer(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "r2_act = gspaces.rot2dOnR2(N=8)\n",
    "in_type = nn.FieldType(r2_act, [r2_act.trivial_repr])\n",
    "out_type = in_type\n",
    "# out_type = nn.FieldType(r2_act, 3*[r2_act.regular_repr])\n",
    "\n",
    "key = jax.random.PRNGKey(0)\n",
    "keys = jax.random.split(key, 8)\n",
    "# model = nn.Linear(in_type, out_type, key=keys[0])\n",
    "# model = nn.Linear(in_type, out_type, key=keys[0])\n",
    "# model = nn.R2Conv(in_type, out_type, kernel_size=4, padding=0, use_bias=False, key=keys[0])\n",
    "model = CNN(key)\n",
    "\n",
    "m = eqx.nn.Linear(1728, 512, key=keys[1])\n",
    "# m = Linear(1728, 512, key=keys[1])\n",
    "#\n",
    "# print(\"jax.tree_util.tree_leaves(m)\",  len(jax.tree_util.tree_leaves(m)), jax.tree_util.tree_leaves(m))\n",
    "# print()\n",
    "# print(hash(tuple(jax.tree_util.tree_leaves(m))))\n",
    "# for e in tuple(jax.tree_util.tree_leaves(m)):\n",
    "#     print(\"e\", e)\n",
    "#     print(\"hash(e)\", hash(e))\n",
    "m = eqx.filter_jit(m)\n",
    "# print(\"jax.tree_util.tree_leaves(m)\", jax.tree_util.tree_leaves(m))\n",
    "# print()\n",
    "input = jax.random.normal(keys[2], (1728,))\n",
    "out = m(input)\n",
    "# print(m(nn.GeometricTensor(input, in_type)))\n",
    "\n",
    "# input = nn.GeometricTensor(x, in_type)\n",
    "\n",
    "# out = model(input)\n",
    "# print(out)\n",
    "# print(model)\n",
    "# print()\n",
    "# print(model.in_type)\n",
    "# print()\n",
    "# print(jax.tree_util.tree_leaves(model))\n",
    "# print()\n",
    "# for e in tuple(jax.tree_util.tree_leaves(model)):\n",
    "#     print(\"e\", e)\n",
    "#     print(\"hash(e)\", hash(e))\n",
    "# print(len(jax.tree_util.tree_leaves(model)))\n",
    "# print(hash(tuple(jax.tree_util.tree_leaves(model))))\n",
    "print(\"jax.tree_util.tree_leaves(model)\", len(jax.tree_util.tree_leaves(model)), jax.tree_util.tree_leaves(model))\n",
    "print()\n",
    "model = eqx.filter_jit(model)#(input)\n",
    "# print(\"jax.tree_util.tree_leaves(model)\", jax.tree_util.tree_leaves(model))\n",
    "# print()\n",
    "# set_trace()\n",
    "# hash(input)\n",
    "# model(input)\n",
    "# print(type(x))\n",
    "# print(\"in_type\", in_type)\n",
    "model(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class C8SteerableCNN(eqx.Module):\n",
    "    layers: list\n",
    "    input_type: nn.FieldType\n",
    "\n",
    "    def __init__(self, key, n_classes=10):\n",
    "        keys = jax.random.split(key, 8)\n",
    "        layers = []\n",
    "        \n",
    "        super(C8SteerableCNN, self).__init__()\n",
    "        \n",
    "        # the model is equivariant under rotations by 45 degrees, modelled by C8\n",
    "        r2_act = gspaces.rot2dOnR2(N=8)\n",
    "        \n",
    "        # the input image is a scalar field, corresponding to the trivial representation\n",
    "        in_type = nn.FieldType(r2_act, [r2_act.trivial_repr])\n",
    "        \n",
    "        # we store the input type for wrapping the images into a geometric tensor during the forward pass\n",
    "        self.input_type = in_type\n",
    "        \n",
    "        # convolution 1\n",
    "        # first specify the output type of the convolutional layer\n",
    "        # we choose 24 feature fields, each transforming under the regular representation of C8\n",
    "        out_type = nn.FieldType(r2_act, 24*[r2_act.regular_repr])\n",
    "        layers.extend([\n",
    "            nn.MaskModule(in_type, 29, margin=1),\n",
    "            nn.R2Conv(in_type, out_type, kernel_size=7, padding=1, use_bias=False, key=keys[0]),\n",
    "            # nn.InnerBatchNorm(out_type),\n",
    "            nn.ReLU(out_type)\n",
    "        ])\n",
    "        \n",
    "        # convolution 2\n",
    "        # the old output type is the input type to the next layer\n",
    "        # in_type = self.block1.out_type\n",
    "        in_type = out_type\n",
    "        # the output type of the second convolution layer are 48 regular feature fields of C8\n",
    "        out_type = nn.FieldType(r2_act, 48*[r2_act.regular_repr])\n",
    "        layers.extend([\n",
    "            nn.R2Conv(in_type, out_type, kernel_size=5, padding=2, use_bias=False, key=keys[1]),\n",
    "            # nn.InnerBatchNorm(out_type),\n",
    "            nn.ReLU(out_type)\n",
    "        ])\n",
    "        layers.append(nn.PointwiseAvgPoolAntialiased(out_type, sigma=0.66, stride=2))\n",
    "        \n",
    "        # convolution 3\n",
    "        # the old output type is the input type to the next layer\n",
    "        # in_type = self.block2.out_type\n",
    "        in_type = out_type\n",
    "        # the output type of the third convolution layer are 48 regular feature fields of C8\n",
    "        out_type = nn.FieldType(r2_act, 48*[r2_act.regular_repr])\n",
    "        layers.extend([\n",
    "            nn.R2Conv(in_type, out_type, kernel_size=5, padding=2, use_bias=False, key=keys[2]),\n",
    "            # nn.InnerBatchNorm(out_type),\n",
    "            nn.ReLU(out_type)\n",
    "        ])\n",
    "        \n",
    "        # convolution 4\n",
    "        # the old output type is the input type to the next layer\n",
    "        # in_type = self.block3.out_type\n",
    "        in_type = out_type\n",
    "        # the output type of the fourth convolution layer are 96 regular feature fields of C8\n",
    "        out_type = nn.FieldType(r2_act, 96*[r2_act.regular_repr])\n",
    "        layers.extend([\n",
    "            nn.R2Conv(in_type, out_type, kernel_size=5, padding=2, use_bias=False, key=keys[3]),\n",
    "            # nn.InnerBatchNorm(out_type),\n",
    "            nn.ReLU(out_type)\n",
    "        ])\n",
    "        layers.append(\n",
    "            nn.PointwiseAvgPoolAntialiased(out_type, sigma=0.66, stride=2)\n",
    "        )\n",
    "        \n",
    "        # convolution 5\n",
    "        # the old output type is the input type to the next layer\n",
    "        # in_type = self.block4.out_type\n",
    "        in_type = out_type\n",
    "        # the output type of the fifth convolution layer are 96 regular feature fields of C8\n",
    "        out_type = nn.FieldType(r2_act, 96*[r2_act.regular_repr])\n",
    "        layers.extend([\n",
    "            nn.R2Conv(in_type, out_type, kernel_size=5, padding=2, use_bias=False, key=keys[4]),\n",
    "            # nn.InnerBatchNorm(out_type),\n",
    "            nn.ReLU(out_type)\n",
    "        ])\n",
    "        \n",
    "        # convolution 6\n",
    "        # the old output type is the input type to the next layer\n",
    "        # in_type = self.block5.out_type\n",
    "        in_type = out_type\n",
    "        # the output type of the sixth convolution layer are 64 regular feature fields of C8\n",
    "        out_type = nn.FieldType(r2_act, 64*[r2_act.regular_repr])\n",
    "        layers.extend([\n",
    "            nn.R2Conv(in_type, out_type, kernel_size=5, padding=1, use_bias=False, key=keys[5]),\n",
    "            # nn.InnerBatchNorm(out_type),\n",
    "            nn.ReLU(out_type)\n",
    "        ])\n",
    "        layers.append(nn.PointwiseAvgPoolAntialiased(out_type, sigma=0.66, stride=1, padding=0))\n",
    "        \n",
    "        layers.append(nn.GroupPooling(out_type))\n",
    "\n",
    "        self.layers = layers\n",
    "        \n",
    "        # number of output channels\n",
    "        # c = self.gpool.out_type.size\n",
    "        c = out_type.size\n",
    "        \n",
    "        # Fully Connected\n",
    "        self.fully_net = eqx.nn.Sequential(\n",
    "            eqx.nn.Linear(c, 64, key=keys[6]),\n",
    "            # eqx.nn.BatchNorm() .BatchNorm1d(64),\n",
    "            jax.nn.elu,\n",
    "            eqx.nn.Linear(64, n_classes, key=keys[7]),\n",
    "        )\n",
    "    \n",
    "    def __call__(self, input: Array):\n",
    "        # wrap the input tensor in a GeometricTensor\n",
    "        # (associate it with the input type)\n",
    "        x = nn.GeometricTensor(input, self.input_type)\n",
    "        \n",
    "        # apply each equivariant block\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "\n",
    "        # unwrap the output GeometricTensor\n",
    "        # (take the Pytorch tensor and discard the associated representation)\n",
    "        x = x.tensor\n",
    "        \n",
    "        # classify with the final fully connected layers)\n",
    "        x = self.fully_net(x.reshape(x.shape[0], -1))\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(eqx.Module):\n",
    "    layers: list\n",
    "    input_type: nn.FieldType\n",
    "    fully_net: list\n",
    "\n",
    "    def __init__(self, key, n_classes=10):\n",
    "        keys = jax.random.split(key, 8)\n",
    "        self.layers = []\n",
    "        \n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        # the model is equivariant under rotations by 45 degrees, modelled by C8\n",
    "        r2_act = gspaces.rot2dOnR2(N=8)\n",
    "        \n",
    "        # the input image is a scalar field, corresponding to the trivial representation\n",
    "        in_type = nn.FieldType(r2_act, [r2_act.trivial_repr])\n",
    "        \n",
    "        # we store the input type for wrapping the images into a geometric tensor during the forward pass\n",
    "        self.input_type = in_type\n",
    "        \n",
    "        # convolution 1\n",
    "        # first specify the output type of the convolutional layer\n",
    "        # we choose 24 feature fields, each transforming under the regular representation of C8\n",
    "        out_type = nn.FieldType(r2_act, 3*[r2_act.regular_repr])\n",
    "        self.layers.extend([\n",
    "            # nn.MaskModule(in_type, 29, margin=1),\n",
    "            nn.R2Conv(in_type, out_type, kernel_size=4, padding=0, use_bias=False, key=keys[0]),\n",
    "            nn.ReLU(out_type),\n",
    "            nn.GroupPooling(out_type)\n",
    "        ])\n",
    "\n",
    "        # block1 = nn.SequentialModule(*[\n",
    "        #     nn.MaskModule(in_type, 29, margin=1),\n",
    "        #     nn.R2Conv(in_type, out_type, kernel_size=4, padding=0, use_bias=False, key=keys[0]),\n",
    "        #     nn.ReLU(out_type),\n",
    "        #     nn.GroupPooling(out_type)\n",
    "        # ])\n",
    "        # self.layers.append(block1)\n",
    "      \n",
    "        # # number of output channels\n",
    "        # # c = self.gpool.out_type.size\n",
    "        # c = block1.out_type.size\n",
    "        # print(\"c\", c)\n",
    "        c = out_type.size\n",
    "        print(\"c\", c)\n",
    "        c = 2028\n",
    "        print(\"c\", c)\n",
    "        \n",
    "        # Fully Connected\n",
    "        # self.fully_net = eqx.nn.Sequential([\n",
    "        self.fully_net = [\n",
    "            eqx.nn.Linear(c, 64, key=keys[6]),\n",
    "            # eqx.nn.BatchNorm() .BatchNorm1d(64),\n",
    "            jax.nn.elu,\n",
    "            eqx.nn.Linear(64, n_classes, key=keys[7]),\n",
    "            jax.nn.log_softmax\n",
    "        ]\n",
    "    \n",
    "    def __call__(self, input: Array):\n",
    "        # wrap the input tensor in a GeometricTensor\n",
    "        # (associate it with the input type)\n",
    "        x = nn.GeometricTensor(input, self.input_type)\n",
    "        # print(\"x\", x.shape)\n",
    "        \n",
    "        # apply each equivariant block\n",
    "        for layer in self.layers:\n",
    "            # print(type(layer))\n",
    "            # print(\"x\", x.shape)\n",
    "            x = layer(x)\n",
    "\n",
    "        # unwrap the output GeometricTensor\n",
    "        # (take the Pytorch tensor and discard the associated representation)\n",
    "        x = x.tensor\n",
    "        # print(\"x\", x.shape)\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        \n",
    "        # classify with the final fully connected layers)\n",
    "        # x = self.fully_net(x.reshape(x.shape[0], -1))\n",
    "        for layer in self.fully_net:\n",
    "            # print(type(layer))\n",
    "            # print(\"x\", x.shape)\n",
    "            x = jax.vmap(layer)(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c 24\n",
      "c 2028\n",
      "CNN(\n",
      "  layers=[\n",
      "    R2Conv(\n",
      "      in_type=[C8_on_R2[(None, 8)]: {irrep_0 (x1)}(1)],\n",
      "      out_type=[C8_on_R2[(None, 8)]: {regular (x3)}(24)],\n",
      "      space=C8_on_R2[(None, 8)],\n",
      "      d=2,\n",
      "      kernel_size=(4, 4),\n",
      "      stride=(1, 1),\n",
      "      dilation=(1, 1),\n",
      "      padding=((0, 0), (0, 0)),\n",
      "      padding_mode='zeros',\n",
      "      groups=1,\n",
      "      _reversed_padding_repeated_twice=(0, 0, 0, 0),\n",
      "      use_bias=False,\n",
      "      _basisexpansion=<escnn.nn.modules.basismanager.basisexpansion_blocks.BlocksBasisExpansion object at 0x7f9366dd11f0>,\n",
      "      bias=None,\n",
      "      filter=f32[24,1,4,4],\n",
      "      weights=f32[15],\n",
      "      bias_expansion=None,\n",
      "      expanded_bias=None,\n",
      "      inference=False,\n",
      "      _rings=[0.0, 1.0],\n",
      "      _sigma=[0.005, 0.4],\n",
      "      _maximum_frequency=2\n",
      "    ),\n",
      "    ReLU(\n",
      "      in_type=[C8_on_R2[(None, 8)]: {regular (x3)}(24)],\n",
      "      out_type=[C8_on_R2[(None, 8)]: {regular (x3)}(24)],\n",
      "      space=C8_on_R2[(None, 8)]\n",
      "    ),\n",
      "    GroupPooling(\n",
      "      in_type=[C8_on_R2[(None, 8)]: {regular (x3)}(24)],\n",
      "      out_type=[C8_on_R2[(None, 8)]: {irrep_0 (x3)}(3)],\n",
      "      space=C8_on_R2[(None, 8)],\n",
      "      in_indices={8: i32[2]},\n",
      "      out_indices={8: i32[2]},\n",
      "      _contiguous={8: True}\n",
      "    )\n",
      "  ],\n",
      "  input_type=[C8_on_R2[(None, 8)]: {irrep_0 (x1)}(1)],\n",
      "  fully_net=[\n",
      "    Linear(\n",
      "      weight=f32[64,2028],\n",
      "      bias=f32[64],\n",
      "      in_features=2028,\n",
      "      out_features=64,\n",
      "      use_bias=True\n",
      "    ),\n",
      "    <wrapped function elu>,\n",
      "    Linear(\n",
      "      weight=f32[10,64],\n",
      "      bias=f32[10],\n",
      "      in_features=64,\n",
      "      out_features=10,\n",
      "      use_bias=True\n",
      "    ),\n",
      "    <wrapped function log_softmax>\n",
      "  ]\n",
      ")\n",
      "(1, 1, 29, 29)\n",
      "(1,)\n",
      "GroupPooling\n",
      "self._contiguous {8: True}\n",
      "8 True\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "Array slice indices must have static start/stop/step to be used with NumPy indexing syntax. Found slice(Traced<ShapedArray(int32[])>with<DynamicJaxprTrace(level=1/0)>, Traced<ShapedArray(int32[])>with<DynamicJaxprTrace(level=1/0)>, None). To index a statically sized array at a dynamic position, try lax.dynamic_slice/dynamic_update_slice (JAX does not support dynamically sized arrays within JIT compiled functions).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 20\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[39mprint\u001b[39m(x\u001b[39m.\u001b[39mshape)\n\u001b[1;32m     19\u001b[0m \u001b[39mprint\u001b[39m(y\u001b[39m.\u001b[39mshape)\n\u001b[0;32m---> 20\u001b[0m eqx\u001b[39m.\u001b[39;49mfilter_jit(model)(x)\n",
      "File \u001b[0;32m~/escnn_jax/venv/lib/python3.9/site-packages/equinox/_jit.py:103\u001b[0m, in \u001b[0;36m_JitWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m/\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 103\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39mFalse\u001b[39;49;00m, args, kwargs)\n",
      "File \u001b[0;32m~/escnn_jax/venv/lib/python3.9/site-packages/equinox/_jit.py:99\u001b[0m, in \u001b[0;36m_JitWrapper._call\u001b[0;34m(self, is_lower, args, kwargs)\u001b[0m\n\u001b[1;32m     97\u001b[0m         out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cached(dynamic, static)\n\u001b[1;32m     98\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 99\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cached(dynamic, static)\n\u001b[1;32m    100\u001b[0m \u001b[39mreturn\u001b[39;00m _postprocess(out)\n",
      "    \u001b[0;31m[... skipping hidden 12 frame]\u001b[0m\n",
      "File \u001b[0;32m~/escnn_jax/venv/lib/python3.9/site-packages/equinox/_jit.py:37\u001b[0m, in \u001b[0;36m_filter_jit_cache.<locals>.fun_wrapped\u001b[0;34m(dynamic, static)\u001b[0m\n\u001b[1;32m     35\u001b[0m fun \u001b[39m=\u001b[39m hashable_combine(dynamic_fun, static_fun)\n\u001b[1;32m     36\u001b[0m args, kwargs \u001b[39m=\u001b[39m hashable_combine(dynamic_spec, static_spec)\n\u001b[0;32m---> 37\u001b[0m out \u001b[39m=\u001b[39m fun(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     38\u001b[0m dynamic_out, static_out \u001b[39m=\u001b[39m partition(out, is_array)\n\u001b[1;32m     39\u001b[0m \u001b[39mreturn\u001b[39;00m dynamic_out, Static(static_out)\n",
      "Cell \u001b[0;32mIn[6], line 69\u001b[0m, in \u001b[0;36mCNN.__call__\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[39m# print(\"x\", x.shape)\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \n\u001b[1;32m     65\u001b[0m \u001b[39m# apply each equivariant block\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers:\n\u001b[1;32m     67\u001b[0m     \u001b[39m# print(type(layer))\u001b[39;00m\n\u001b[1;32m     68\u001b[0m     \u001b[39m# print(\"x\", x.shape)\u001b[39;00m\n\u001b[0;32m---> 69\u001b[0m     x \u001b[39m=\u001b[39m layer(x)\n\u001b[1;32m     71\u001b[0m \u001b[39m# unwrap the output GeometricTensor\u001b[39;00m\n\u001b[1;32m     72\u001b[0m \u001b[39m# (take the Pytorch tensor and discard the associated representation)\u001b[39;00m\n\u001b[1;32m     73\u001b[0m x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mtensor\n",
      "File \u001b[0;32m~/escnn_jax/notebooks/../escnn/nn/modules/invariantmaps/gpool.py:126\u001b[0m, in \u001b[0;36mGroupPooling.__call__\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    123\u001b[0m out_indices \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mout_indices[s]\n\u001b[1;32m    125\u001b[0m \u001b[39mif\u001b[39;00m contiguous:\n\u001b[0;32m--> 126\u001b[0m     fm \u001b[39m=\u001b[39m \u001b[39minput\u001b[39;49m[:, in_indices[\u001b[39m0\u001b[39;49m]:in_indices[\u001b[39m1\u001b[39;49m], \u001b[39m.\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m.\u001b[39;49m]\n\u001b[1;32m    127\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    128\u001b[0m     fm \u001b[39m=\u001b[39m \u001b[39minput\u001b[39m[:, in_indices, \u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m]\n",
      "File \u001b[0;32m~/escnn_jax/venv/lib/python3.9/site-packages/jax/_src/numpy/array_methods.py:791\u001b[0m, in \u001b[0;36m_forward_operator_to_aval.<locals>.op\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    790\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mop\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs):\n\u001b[0;32m--> 791\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mgetattr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49maval, \u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m_\u001b[39;49m\u001b[39m{\u001b[39;49;00mname\u001b[39m}\u001b[39;49;00m\u001b[39m\"\u001b[39;49m)(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs)\n",
      "File \u001b[0;32m~/escnn_jax/venv/lib/python3.9/site-packages/jax/_src/numpy/lax_numpy.py:4143\u001b[0m, in \u001b[0;36m_rewriting_take\u001b[0;34m(arr, idx, indices_are_sorted, unique_indices, mode, fill_value)\u001b[0m\n\u001b[1;32m   4140\u001b[0m       \u001b[39mreturn\u001b[39;00m lax\u001b[39m.\u001b[39mdynamic_index_in_dim(arr, idx, keepdims\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m   4142\u001b[0m treedef, static_idx, dynamic_idx \u001b[39m=\u001b[39m _split_index_for_jit(idx, arr\u001b[39m.\u001b[39mshape)\n\u001b[0;32m-> 4143\u001b[0m \u001b[39mreturn\u001b[39;00m _gather(arr, treedef, static_idx, dynamic_idx, indices_are_sorted,\n\u001b[1;32m   4144\u001b[0m                unique_indices, mode, fill_value)\n",
      "File \u001b[0;32m~/escnn_jax/venv/lib/python3.9/site-packages/jax/_src/numpy/lax_numpy.py:4152\u001b[0m, in \u001b[0;36m_gather\u001b[0;34m(arr, treedef, static_idx, dynamic_idx, indices_are_sorted, unique_indices, mode, fill_value)\u001b[0m\n\u001b[1;32m   4149\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_gather\u001b[39m(arr, treedef, static_idx, dynamic_idx, indices_are_sorted,\n\u001b[1;32m   4150\u001b[0m             unique_indices, mode, fill_value):\n\u001b[1;32m   4151\u001b[0m   idx \u001b[39m=\u001b[39m _merge_static_and_dynamic_indices(treedef, static_idx, dynamic_idx)\n\u001b[0;32m-> 4152\u001b[0m   indexer \u001b[39m=\u001b[39m _index_to_gather(shape(arr), idx)  \u001b[39m# shared with _scatter_update\u001b[39;00m\n\u001b[1;32m   4153\u001b[0m   y \u001b[39m=\u001b[39m arr\n\u001b[1;32m   4155\u001b[0m   \u001b[39mif\u001b[39;00m fill_value \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/escnn_jax/venv/lib/python3.9/site-packages/jax/_src/numpy/lax_numpy.py:4404\u001b[0m, in \u001b[0;36m_index_to_gather\u001b[0;34m(x_shape, idx, normalize_indices)\u001b[0m\n\u001b[1;32m   4395\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mall\u001b[39m(_is_slice_element_none_or_constant(elt)\n\u001b[1;32m   4396\u001b[0m            \u001b[39mfor\u001b[39;00m elt \u001b[39min\u001b[39;00m (start, stop, step)):\n\u001b[1;32m   4397\u001b[0m   msg \u001b[39m=\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39mArray slice indices must have static start/stop/step to be used \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   4398\u001b[0m          \u001b[39m\"\u001b[39m\u001b[39mwith NumPy indexing syntax. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   4399\u001b[0m          \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFound slice(\u001b[39m\u001b[39m{\u001b[39;00mstart\u001b[39m}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m{\u001b[39;00mstop\u001b[39m}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m{\u001b[39;00mstep\u001b[39m}\u001b[39;00m\u001b[39m). \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4402\u001b[0m          \u001b[39m\"\u001b[39m\u001b[39mdynamic_update_slice (JAX does not support dynamically sized \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   4403\u001b[0m          \u001b[39m\"\u001b[39m\u001b[39marrays within JIT compiled functions).\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 4404\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mIndexError\u001b[39;00m(msg)\n\u001b[1;32m   4405\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m core\u001b[39m.\u001b[39mis_constant_dim(x_shape[x_axis]):\n\u001b[1;32m   4406\u001b[0m   msg \u001b[39m=\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39mCannot use NumPy slice indexing on an array dimension whose \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   4407\u001b[0m          \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39msize is not statically known (\u001b[39m\u001b[39m{\u001b[39;00mx_shape[x_axis]\u001b[39m}\u001b[39;00m\u001b[39m). \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   4408\u001b[0m          \u001b[39m\"\u001b[39m\u001b[39mTry using lax.dynamic_slice/dynamic_update_slice\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mIndexError\u001b[0m: Array slice indices must have static start/stop/step to be used with NumPy indexing syntax. Found slice(Traced<ShapedArray(int32[])>with<DynamicJaxprTrace(level=1/0)>, Traced<ShapedArray(int32[])>with<DynamicJaxprTrace(level=1/0)>, None). To index a statically sized array at a dynamic position, try lax.dynamic_slice/dynamic_update_slice (JAX does not support dynamically sized arrays within JIT compiled functions)."
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 64\n",
    "LEARNING_RATE = 3e-4\n",
    "STEPS = 300\n",
    "PRINT_EVERY = 30\n",
    "SEED = 5678\n",
    "\n",
    "key = jax.random.PRNGKey(SEED)\n",
    "\n",
    "key, subkey = jax.random.split(key, 2)\n",
    "# model = C8SteerableCNN(subkey)\n",
    "model = CNN(subkey)\n",
    "# model = jax.jit(model)\n",
    "print(model)\n",
    "\n",
    "x, y = mnist_train[0]\n",
    "x = jnp.array(x[None, ...])\n",
    "y = jnp.array(y[None, ...])\n",
    "print(x.shape)\n",
    "print(y.shape)\n",
    "eqx.filter_jit(model)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model: eqx.Module, x: Image):\n",
    "    np.set_printoptions(linewidth=10000)\n",
    "    \n",
    "    # evaluate the `model` on 8 rotated versions of the input image `x`\n",
    "    # model = model.eval()\n",
    "    \n",
    "    x = resize1(pad(x))\n",
    "    \n",
    "    print()\n",
    "    print('##########################################################################################')\n",
    "    header = 'angle |  ' + '  '.join([\"{:6d}\".format(d) for d in range(10)])\n",
    "    print(header)\n",
    "    # with torch.no_grad():\n",
    "    for r in range(8):\n",
    "        x_transformed = totensor(resize2(x.rotate(r*45., Image.BILINEAR))).reshape(1, 1, 29, 29)\n",
    "        # print(\"x_transformed\", type(x_transformed), x_transformed)\n",
    "        x_transformed = jnp.array(x_transformed.numpy())#.to(device)\n",
    "\n",
    "        y = model(x_transformed)\n",
    "        # y = y.to('cpu').numpy().squeeze()\n",
    "        y = np.array(y).squeeze()\n",
    "        \n",
    "        angle = r * 45\n",
    "        print(\"{:5d} : {}\".format(angle, y))\n",
    "    print('##########################################################################################')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##########################################################################################\n",
      "angle |       0       1       2       3       4       5       6       7       8       9\n",
      "    0 : [-2.3039029 -2.3758793 -2.261747  -2.417113  -2.3186145 -2.2233348 -2.3939812 -2.445771  -2.1761634 -2.155946 ]\n",
      "   45 : [-2.3090162 -2.330779  -2.20519   -2.4289494 -2.3360045 -2.3187938 -2.3918345 -2.3799646 -2.188079  -2.173234 ]\n",
      "   90 : [-2.2690861 -2.374911  -2.2361343 -2.4105105 -2.3555703 -2.2416685 -2.4006789 -2.4494424 -2.1421843 -2.1945066]\n",
      "  135 : [-2.3045998 -2.3854792 -2.2522273 -2.4654298 -2.288461  -2.1792316 -2.3682797 -2.4039762 -2.1915684 -2.2281508]\n",
      "  180 : [-2.3038316 -2.4193363 -2.1862879 -2.431365  -2.294912  -2.28298   -2.3901792 -2.4280572 -2.1476018 -2.193202 ]\n",
      "  225 : [-2.2785158 -2.3578658 -2.2640278 -2.4308782 -2.2774334 -2.2697644 -2.4253724 -2.395699  -2.1898189 -2.1743972]\n",
      "  270 : [-2.2624114 -2.3587322 -2.2226477 -2.4149845 -2.3286276 -2.2724388 -2.393867  -2.4467957 -2.184493  -2.1821477]\n",
      "  315 : [-2.2853632 -2.307637  -2.2828956 -2.325696  -2.3668942 -2.3386247 -2.4684837 -2.4458451 -2.1241806 -2.1376278]\n",
      "##########################################################################################\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# build the test set    \n",
    "raw_mnist_test = MnistRotDataset(mode='test')\n",
    "# retrieve the first image from the test set\n",
    "x, y = next(iter(raw_mnist_test))\n",
    "\n",
    "# evaluate the model\n",
    "test_model(model, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "() 2.4092078\n",
      "2.4092078\n"
     ]
    }
   ],
   "source": [
    "def loss(\n",
    "    # model, x: Float[Array, \"batch 1 28 28\"], y: Int[Array, \" batch\"]\n",
    "    model, x: Float[Array, \"batch 1 29 29\"], y: Int[Array, \" batch\"]\n",
    ") -> Float[Array, \"\"]:\n",
    "    # Our input has the shape (BATCH_SIZE, 1, 28, 28), but our model operations on\n",
    "    # a single input input image of shape (1, 28, 28).\n",
    "    #\n",
    "    # Therefore, we have to use jax.vmap, which in this case maps our model over the\n",
    "    # leading (batch) axis.\n",
    "    # pred_y = jax.vmap(model)(x)\n",
    "    pred_y = model(x)\n",
    "    return cross_entropy(y, pred_y)\n",
    "\n",
    "\n",
    "def cross_entropy(\n",
    "    y: Int[Array, \" batch\"], pred_y: Float[Array, \"batch 10\"]\n",
    ") -> Float[Array, \"\"]:\n",
    "    # y are the true targets, and should be integers 0-9.\n",
    "    # pred_y are the log-softmax'd predictions.\n",
    "    pred_y = jnp.take_along_axis(pred_y, jnp.expand_dims(y, 1), axis=1)\n",
    "    return -jnp.mean(pred_y)\n",
    "\n",
    "\n",
    "# Example loss\n",
    "loss_value = loss(model, x, y)\n",
    "print(loss_value.shape, loss_value)  # scalar loss\n",
    "# Example inference\n",
    "# output = jax.vmap(model)(x)\n",
    "# output = jax.jit(model)(x)\n",
    "output = model(x)\n",
    "\n",
    "\n",
    "# This will work!\n",
    "# params, static = eqx.partition(model, eqx.is_array)\n",
    "\n",
    "\n",
    "# def loss2(params, static, x, y):\n",
    "#     model = eqx.combine(params, static)\n",
    "#     return loss(model, x, y)\n",
    "\n",
    "\n",
    "# loss_value, grads = jax.value_and_grad(loss2)(params, static, x, y)\n",
    "# print(loss_value)\n",
    "\n",
    "# This will work too!\n",
    "value, grads = eqx.filter_value_and_grad(loss)(model, x, y)\n",
    "print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Array(2.3148353, dtype=float32), Array(0.09828565, dtype=float32))"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loss = eqx.filter_jit(loss)  # JIT our loss function from earlier!\n",
    "\n",
    "\n",
    "# @eqx.filter_jit\n",
    "def compute_accuracy(\n",
    "    model: CNN, x: Float[Array, \"batch 1 28 28\"], y: Int[Array, \" batch\"]\n",
    ") -> Float[Array, \"\"]:\n",
    "    \"\"\"This function takes as input the current model\n",
    "    and computes the average accuracy on a batch.\n",
    "    \"\"\"\n",
    "    # pred_y = jax.vmap(model)(x)\n",
    "    pred_y = model(x)\n",
    "    pred_y = jnp.argmax(pred_y, axis=1)\n",
    "    return jnp.mean(y == pred_y)\n",
    "\n",
    "def evaluate(model: CNN, testloader: torch.utils.data.DataLoader):\n",
    "    \"\"\"This function evaluates the model on the test dataset,\n",
    "    computing both the average loss and the average accuracy.\n",
    "    \"\"\"\n",
    "    avg_loss = 0\n",
    "    avg_acc = 0\n",
    "    for x, y in testloader:\n",
    "        x = jnp.array(x.numpy())\n",
    "        y = jnp.array(y.numpy())\n",
    "        # Note that all the JAX operations happen inside `loss` and `compute_accuracy`,\n",
    "        # and both have JIT wrappers, so this is fast.\n",
    "        avg_loss += loss(model, x, y)\n",
    "        avg_acc += compute_accuracy(model, x, y)\n",
    "    return avg_loss / len(testloader), avg_acc / len(testloader)\n",
    "\n",
    "evaluate(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optax\n",
    "optim = optax.adamw(LEARNING_RATE)\n",
    "\n",
    "def train(\n",
    "    model: CNN,\n",
    "    trainloader: torch.utils.data.DataLoader,\n",
    "    testloader: torch.utils.data.DataLoader,\n",
    "    optim: optax.GradientTransformation,\n",
    "    steps: int,\n",
    "    print_every: int,\n",
    ") -> CNN:\n",
    "    # Just like earlier: It only makes sense to train the arrays in our model,\n",
    "    # so filter out everything else.\n",
    "    opt_state = optim.init(eqx.filter(model, eqx.is_array))\n",
    "\n",
    "    # Always wrap everything -- computing gradients, running the optimiser, updating\n",
    "    # the model -- into a single JIT region. This ensures things run as fast as\n",
    "    # possible.\n",
    "    # @eqx.filter_jit\n",
    "    def make_step(\n",
    "        model: CNN,\n",
    "        opt_state: PyTree,\n",
    "        # x: Float[Array, \"batch 1 28 28\"],\n",
    "        x: Float[Array, \"batch 1 29 29\"],\n",
    "        y: Int[Array, \" batch\"],\n",
    "    ):\n",
    "        loss_value, grads = eqx.filter_value_and_grad(loss)(model, x, y)\n",
    "        updates, opt_state = optim.update(grads, opt_state, model)\n",
    "        model = eqx.apply_updates(model, updates)\n",
    "        return model, opt_state, loss_value\n",
    "\n",
    "    # Loop over our training dataset as many times as we need.\n",
    "    def infinite_trainloader():\n",
    "        while True:\n",
    "            yield from train_loader\n",
    "\n",
    "    for step, (x, y) in zip(range(steps), infinite_trainloader()):\n",
    "        # PyTorch dataloaders give PyTorch tensors by default,\n",
    "        # so convert them to NumPy arrays.\n",
    "        x = jnp.array(x.numpy())\n",
    "        y = jnp.array(y.numpy())\n",
    "        model, opt_state, train_loss = make_step(model, opt_state, x, y)\n",
    "        if (step % print_every) == 0 or (step == steps - 1):\n",
    "            test_loss, test_accuracy = evaluate(model, testloader)\n",
    "            print(\n",
    "                f\"{step=}, train_loss={train_loss.item()}, \"\n",
    "                f\"test_loss={test_loss.item()}, test_accuracy={test_accuracy.item()}\"\n",
    "            )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step=0, train_loss=2.292130947113037, test_loss=2.3077950477600098, test_accuracy=0.12965552508831024\n",
      "step=30, train_loss=2.1808724403381348, test_loss=2.1475913524627686, test_accuracy=0.27635470032691956\n",
      "step=60, train_loss=2.042396068572998, test_loss=1.99031400680542, test_accuracy=0.34325048327445984\n",
      "step=90, train_loss=1.8445414304733276, test_loss=1.8483741283416748, test_accuracy=0.4116847813129425\n",
      "step=120, train_loss=1.801900863647461, test_loss=1.7456316947937012, test_accuracy=0.4030730426311493\n",
      "step=150, train_loss=1.606579303741455, test_loss=1.6744093894958496, test_accuracy=0.4048313498497009\n",
      "step=180, train_loss=1.609127163887024, test_loss=1.6039823293685913, test_accuracy=0.4306465685367584\n",
      "step=210, train_loss=1.4931309223175049, test_loss=1.5789670944213867, test_accuracy=0.44057703018188477\n",
      "step=240, train_loss=1.5692706108093262, test_loss=1.5438400506973267, test_accuracy=0.44037723541259766\n",
      "step=270, train_loss=1.3343498706817627, test_loss=1.529144525527954, test_accuracy=0.44830963015556335\n",
      "step=299, train_loss=1.4047878980636597, test_loss=1.5296690464019775, test_accuracy=0.45362451672554016\n"
     ]
    }
   ],
   "source": [
    "model = train(model, train_loader, test_loader, optim, STEPS, PRINT_EVERY)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
